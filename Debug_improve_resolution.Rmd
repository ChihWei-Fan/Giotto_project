---
title: "Debug_improve_resolution"
output: html_document
date: "2023-09-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Check how amny clusters belongs to the edge clusters ()

```{r - **merge tiles with all clusters**}
# comb_res is a dataframe which has the tiles name and the cluster the tile belongs to
#Get all the filenames of tiles in a list 
load("/projectnb/rd-spat/HOME/ivycwf/project_1/resolution/s119B_89x103_tiles/entireHnE_kmean8_pca10_it500_star100.RData")

# Create an empty list to store the raster objects
fftiles <- list()
fftile_rows <- list()

# Function to load raster and preprocess
load_and_preprocess_raster <- function(tile_name) {
  tile <- terra::rast(tile_name)
  if (is.na(any(terra::values(tile) > 255) || any(terra::values(tile) < 0))) {
      tile_values <- terra::values(tile)
      NaN_rows <- which(apply(tile_values, 1, function(row) all(is.nan(row))))
      tile_values[NaN_rows, 1] <- 179
      tile_values[NaN_rows, 2] <- 184
      tile_values[NaN_rows, 3] <- 168
      terra::values(tile) <- tile_values
  }
  return(tile)
}

# Iterate over each kmean value and create a plot
for (kmean_val in 1:4) {
  # Get the corresponding tile names for the current kmean value
  tile_names <- lapply(comb_res[comb_res$kmeans == kmean_val, 1], function(x) paste0('/projectnb/rd-spat/HOME/ivycwf/project_1/resolution/s119B_89x103_tiles/', x))
  
  # Load each raster into the list and preprocess
  fftiles <- lapply(tile_names, load_and_preprocess_raster)
  
  # Stack the rasters in the list on top of each other
  fftiles_ls <- terra::sprc(fftiles)
  merge_image <- terra::merge(fftiles_ls)
  
  # Plot the merged raster
  plot_title <- paste("Kmeans =", kmean_val)
  terra::plot(merge_image, main = plot_title)
}

```



## There are too many clusters occupied by edge clusters, 


```{r}

```




#Modeling
```{r}
#Model 1: LASSO model
#fit	LASSO,	need	a	random	seed	because	cross-validation	is	involved	 
#APOE_las_cv <- cv.glmnet(x = as.matrix(training_set[,-c(1, 2050, 2051)]), y = training_set$APOE, alpha = 1)
SPARC_las_cv <- cv.glmnet(x = as.matrix(training_set[,-c(1, 2050, 2051)]), y = training_set$SPARC, alpha = 1)

#Get the optimal lambda
#opt_lambda <-APOE_las_cv$lambda.min
opt_lambda <-SPARC_las_cv$lambda.min

#produce plot of test MSE by lambda value
#plot(APOE_las_cv) #why k is 1???
plot(SPARC_las_cv)

#find coefficients of best model
#APOE_las <-glmnet( x = as.matrix(training_set[,-c(1,2050, 2051)]), y = training_set$APOE, alpha = 1, lambda = opt_lambda)
SPARC_las <-glmnet( x = as.matrix(training_set[,-c(1,2050, 2051)]), y = training_set$SPARC, alpha = 1, lambda = opt_lambda)


#coef(APOE_las)
coef(SPARC_las)
#No coefficient is shown for the predictor (all original features) because lasso regression shrunk the coefficient all the way to zero. This means it was completely dropped from the model because it wasnâ€™t influential enough.

# Make predictions on the test set
#APOE_preds <- predict(APOE_las, newx =  as.matrix(test_set[,-c(1, 2050, 2051)]), type = "response", s= opt_lambda)
SPARC_preds <- predict(SPARC_las, newx =  as.matrix(test_set[,-c(1, 2050, 2051)]), type = "response", s= opt_lambda)

mse =  mean((test_set$SPARC - SPARC_preds)^2) 
mae = MAE(test_set$SPARC, SPARC_preds)
rmse = RMSE(test_set$SPARC, SPARC_preds)
r2 = R2(test_set$SPARC, SPARC_preds, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

plot(test_set$SPARC, SPARC_preds)
scatter.smooth(test_set$SPARC, SPARC_preds)
cor(test_set$SPARC, SPARC_preds)


```



#Model 1: #LASSO or elasticnet (glmnet) not using lm because linear regression model need more observations than variables(features) so the PC could be more reliable. -- use original features
```{r}
#Model 1 -- LASSO (another method)
#Create control
control <- trainControl(method="cv",                            
                        number = 10,                            
                        summaryFunction = defaultSummary,                         
                        savePredictions = 'all')


#data preprocessing can also be done in train() function
SPARC_glmnet <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050)],                    
                     method = "glmnet",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Make predictions on the test set
SPARC_preds <- predict(SPARC_glmnet, newdata = test_set[,c(2:2049)], type = "raw")

#Generate confusion matrix
cm_SPARC_lso = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_lso <- merge(tile_plot_df[match(cm_SPARC_lso$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_lso, by = "tile_name")


mse =  mean((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred))
rmse = sum((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2)/sum((cm_SPARC_lso$SPARC - mean(cm_SPARC_lso$SPARC))^2)
Pearson = cor(cm_SPARC_lso$SPARC, cm_SPARC_lso$SPARC_pred, method = "pearson")
r2 = R2(cm_SPARC_lso$SPARC, cm_SPARC_lso$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2, "\n", "Pearson:", Pearson)


#Plot predicted expression
ggplot(cm_SPARC_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_SPARC_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
head(cm_SPARC_lso)

ggscatter(cm_SPARC_lso, x = "SPARC", y = "SPARC_pred", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          add.params = list(color = "blue", fill = "lightgray"),
          xlab = "Observed SPARC Expression", ylab = "Predicted SPARC Expression",
          size = 1.5, cor.coef.size = 5)

```



#Model 1 -- LASSO for SPARC (with COL1A1 & LUM)
```{r}
#data preprocessing can also be done in train() function
SPARC_glmnet <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050:2060)],                    
                     method = "glmnet",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Make predictions on the test set
SPARC_preds <- predict(SPARC_glmnet, newdata = test_set[,c(2:2049,2051:2060)], type = "raw")

#Generate confusion matrix
cm_SPARC_lso = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_lso <- merge(tile_plot_df[match(cm_SPARC_lso$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_lso, by = "tile_name")


mse =  mean((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred))
rmse = sum((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2)/sum((cm_SPARC_lso$SPARC - mean(cm_SPARC_lso$SPARC))^2)
r2 = R2(cm_SPARC_lso$SPARC, cm_SPARC_lso$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)


#Plot predicted expression
ggplot(cm_SPARC_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_SPARC_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
head(cm_SPARC_lso)

```





# Model 1 --LASSO for COL1A1
```{r}
#Model 1 -- LASSO (another method)

#data preprocessing can also be done in train() function
COL1A1_glmnet <- caret::train(COL1A1~.,                      
                     data = training_set[,c(2:2049,2051)],                
                     method = "glmnet",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Make predictions on the test set
COL1A1_preds <- predict(COL1A1_glmnet, newdata = test_set[,c(2:2049)], type = "raw")

#Generate confusion matrix
cm_COL1A1_lso = data.frame( COL1A1 = test_set["COL1A1"], COL1A1_pred = COL1A1_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_COL1A1_lso <- merge(tile_plot_df[match(cm_COL1A1_lso$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_COL1A1_lso, by = "tile_name")


mse =  mean((cm_COL1A1_lso$COL1A1 - cm_COL1A1_lso$COL1A1_pred)^2) 
mae = mean(abs(cm_COL1A1_lso$COL1A1 - cm_COL1A1_lso$COL1A1_pred))
rmse = sum((cm_COL1A1_lso$COL1A1 - cm_COL1A1_lso$COL1A1_pred)^2)/sum((cm_COL1A1_lso$COL1A1 - mean(cm_COL1A1_lso$COL1A1))^2)
r2 = R2(cm_COL1A1_lso$COL1A1, cm_COL1A1_lso$COL1A1_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Plot predicted expression
ggplot(cm_COL1A1_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = COL1A1_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_COL1A1_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = COL1A1)) +
  scale_colour_gradient2()
head(cm_COL1A1_lso)

```
# Model 1 --LASSO for COL1A1 (with SPARC & LUM)
```{r}
#Model 1 -- LASSO (another method)

#data preprocessing can also be done in train() function
COL1A1_glmnet <- caret::train(COL1A1~.,                      
                     data = training_set[,c(2:2049,2050:2052)],                
                     method = "glmnet",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Make predictions on the test set
COL1A1_preds <- predict(COL1A1_glmnet, newdata = test_set[,c(2:2049,2050,2052)], type = "raw")

#Generate confusion matrix
cm_COL1A1_lso = data.frame( COL1A1 = test_set["COL1A1"], COL1A1_pred = COL1A1_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_COL1A1_lso <- merge(tile_plot_df[match(cm_COL1A1_lso$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_COL1A1_lso, by = "tile_name")


mse =  mean((cm_COL1A1_lso$COL1A1 - cm_COL1A1_lso$COL1A1_pred)^2) 
mae = mean(abs(cm_COL1A1_lso$COL1A1 - cm_COL1A1_lso$COL1A1_pred))
rmse = sum((cm_COL1A1_lso$COL1A1 - cm_COL1A1_lso$COL1A1_pred)^2)/sum((cm_COL1A1_lso$COL1A1 - mean(cm_COL1A1_lso$COL1A1))^2)
r2 = R2(cm_COL1A1_lso$COL1A1, cm_COL1A1_lso$COL1A1_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Plot predicted expression
ggplot(cm_COL1A1_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = COL1A1_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_COL1A1_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = COL1A1)) +
  scale_colour_gradient2()
head(cm_COL1A1_lso)

```

# Model 1 --LASSO for LUM
```{r}
#Model 1 -- LASSO (another method)

#data preprocessing can also be done in train() function
LUM_glmnet <- caret::train(LUM~.,                      
                     data = training_set[,c(2:2049,2052)],           
                     method = "glmnet",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Make predictions on the test set
LUM_preds <- predict(LUM_glmnet, newdata = test_set[,c(2:2049)], type = "raw")

#Generate confusion matrix
cm_LUM = data.frame( LUM = test_set["LUM"], LUM_pred = LUM_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_LUM <- merge(tile_plot_df[match(cm_LUM$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_LUM, by = "tile_name")


mse =  mean((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred))
rmse = sum((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2)/sum((cm_SPARC_lso$SPARC - mean(cm_SPARC_lso$SPARC))^2)
r2 = R2(cm_SPARC_lso$SPARC, cm_SPARC_lso$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

```
# Model 1 --LASSO for LUM (with SPARC and COL1A1)
```{r}
#Model 1 -- LASSO (another method)

#data preprocessing can also be done in train() function
LUM_glmnet <- caret::train(LUM~.,                      
                     data = training_set[,c(2:2049,2050:2052)],           
                     method = "glmnet",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Make predictions on the test set
LUM_preds <- predict(LUM_glmnet, newdata = test_set[,c(2:2049, 2050, 2051)], type = "raw")

#Generate confusion matrix
cm_LUM = data.frame( LUM = test_set["LUM"], LUM_pred = LUM_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_LUM <- merge(tile_plot_df[match(cm_LUM$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_LUM, by = "tile_name")


mse =  mean((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred))
rmse = sum((cm_SPARC_lso$SPARC - cm_SPARC_lso$SPARC_pred)^2)/sum((cm_SPARC_lso$SPARC - mean(cm_SPARC_lso$SPARC))^2)
r2 = R2(cm_SPARC_lso$SPARC, cm_SPARC_lso$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

```


#Prepare df for ploting prediciton result
```{r}
#Prepare df for ploting
traing_testdf <- merge(training_set, tile_plot_df[tile_plot_df$tile_name %in% training_set$tile_name, c("tile_name","x_cor","y_cor")], by = "tile_name")
testing_testdf <- merge(test_set, tile_plot_df[tile_plot_df$tile_name %in% test_set$tile_name, c("tile_name","x_cor","y_cor")], by = "tile_name")
train_n_test_testdf <- rbind(traing_testdf, testing_testdf)

```

#Plotting results
```{r}
#Plot predict expression
ggplot(cm_SPARC_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_pred)) +
    scale_colour_gradient2(low = "blue", high = "red" )

#Plot visium gene expression (test set)
ggplot(cm_SPARC_lso, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
    scale_colour_gradient2(low = "blue", high = "red" )

#Plot visium gene expression (training set)
ggplot(traing_testdf, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
    scale_colour_gradient2(low = "blue", high = "red" )

#Plot visium gene expression (entire dataset)
ggplot(train_n_test_testdf, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
    scale_colour_gradient2(low = "blue", high = "red" )

###Check the correctness of the ploting result (training set + testing set)
combined_data <- rbind(data.frame(x_cor = cm_SPARC_lso$x_cor, y_cor = cm_SPARC_lso$y_cor, SPARC = cm_SPARC_lso$SPARC, dataset = "Lasso"),
                       data.frame(x_cor = traing_testdf$x_cor, y_cor = traing_testdf$y_cor, SPARC = traing_testdf$SPARC, dataset = "Training Set"))

# Plot combined data
ggplot(combined_data, aes(x = x_cor, y = y_cor, color = SPARC, shape = dataset)) +
  geom_point() +
  scale_colour_gradient2(low = "blue", high = "red" ) #scale_colour_gradient2(low = scales::muted("blue"), high = scales::muted("red") )

#check the distribution of variable with the histogram-- check if is's scaled
```

#Model 2: Random Forest model 
```{r}
SPARC_rf <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050)],    #training_set[,-c(1,2007)]                
                     method = "rf",                      
                     metric = "RMSE",                      
                     trControl = control) 

#the independent observation is violated (the data is correlated)
#SPARC_rf <- randomForest(SPARC ~ ., data = training_set[, -c(1, 2051)], importance = TRUE)

# Make predictions on the test set
SPARC_rf_preds <- predict(SPARC_rf, newdata = test_set[,c(2:2049)], type = "raw")

#Generate confusion matrix
cm_SPARC_rf = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_rf_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_rf <- merge(tile_plot_df[match(cm_SPARC_rf$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_rf, by = "tile_name")

mse =  mean((cm_SPARC_rf$SPARC - cm_SPARC_rf$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_rf$SPARC - cm_SPARC_rf$SPARC_pred))
rmse = sum((cm_SPARC_rf$SPARC - cm_SPARC_rf$SPARC_pred)^2)/sum((cm_SPARC_rf$SPARC - mean(cm_SPARC_rf$SPARC))^2)
r2 = R2(cm_SPARC_rf$SPARC, cm_SPARC_rf$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Plot predicted expression
ggplot(cm_SPARC_rf, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_SPARC_rf, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
head(cm_SPARC_nn)


```
#Model 2: Random Forest model (with COL1A1 and LUM)
```{r}
SPARC_rf <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050:2052)],    #training_set[,-c(1,2007)]                
                     method = "rf",                      
                     metric = "RMSE",                      
                     trControl = control) 

#the independent observation is violated (the data is correlated)
#SPARC_rf <- randomForest(SPARC ~ ., data = training_set[, -c(1, 2051)], importance = TRUE)

# Make predictions on the test set
SPARC_rf_preds <- predict(SPARC_rf, newdata = test_set[,c(2:2049, 2051, 2052)], type = "raw")

#Generate confusion matrix
cm_SPARC_rf = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_rf_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_rf <- merge(tile_plot_df[match(cm_SPARC_rf$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_rf, by = "tile_name")

mse =  mean((cm_SPARC_rf$SPARC - cm_SPARC_rf$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_rf$SPARC - cm_SPARC_rf$SPARC_pred))
rmse = sum((cm_SPARC_rf$SPARC - cm_SPARC_rf$SPARC_pred)^2)/sum((cm_SPARC_rf$SPARC - mean(cm_SPARC_rf$SPARC))^2)
r2 = R2(cm_SPARC_rf$SPARC, cm_SPARC_rf$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Plot predicted expression
ggplot(cm_SPARC_rf, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_SPARC_rf, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
head(cm_SPARC_rf)


```
#Model 2 : Neutral Network (neuralnet)
```{r}
library(neuralnet)

SPARC_nn <- caret::train(
  SPARC ~ .,
  data = training_set[,c(2:2049,2050)],
  method = "neuralnet",
  metric = "RMSE",
  trControl = control
)

SPARC_nn_preds <-predict(SPARC_nn, newdata = test_set[,c(2:2049)])

#Generate confusion matrix
cm_SPARC_nn = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_nn_preds, tile_name = test_set[,1])

#Generate confusion matrix
cm_SPARC_nn = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_nn_preds, tile_name = test_set[,1])

cm_SPARC_nn <- merge(tile_plot_df[match(cm_SPARC_nn$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_nn, by = "tile_name")

mse =  mean((cm_SPARC_nn$SPARC - cm_SPARC_nn$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_nn$SPARC - cm_SPARC_nn$SPARC_pred))
rmse = sum((cm_SPARC_nn$SPARC - cm_SPARC_nn$SPARC_pred)^2)/sum((cm_SPARC_nn$SPARC - mean(cm_SPARC_nn$SPARC))^2)
r2 = R2(cm_SPARC_nn$SPARC, cm_SPARC_nn$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Plot predicted expression
ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

#Plot observed expression
ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
head(cm_SPARC_nn)
```



#Model 3: Random Forest GBM model
```{r}
library(gbm) 
SPARC_gbm <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050)],    #training_set[,-c(1,2007)]                
                     method = "gbm",                      
                     metric = "RSME",                      
                     trControl = control) 

# Make predictions on the test set
SPARC_gbm_preds <- predict(SPARC_gbm, newdata = test_set[,c(2:2049)], type = "raw")


#Generate confusion matrix
cm_SPARC_gbm = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_gbm_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_gbm <- merge(tile_plot_df[match(cm_SPARC_gbm$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_gbm, by = "tile_name")

mse =  mean((cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred))
rmse = sum((cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred)^2)/sum((cm_SPARC_gbm$SPARC - mean(cm_SPARC_gbm$SPARC))^2)
r2 = R2(cm_SPARC_gbm$SPARC, cm_SPARC_gbm$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Polt predict expression
ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
```
```{r}
ggscatter(cm_SPARC_gbm, x = "SPARC", y = "SPARC_pred", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Observed SPARC Expression", ylab = "Predicted SPARC Expression")
```


#Model 3: Random Forest GBM model (with COL1A1 and LUM)
```{r}
library(gbm) 
SPARC_gbm <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050:2060)],    #training_set[,-c(1,2007)]                
                     method = "gbm",                      
                     metric = "RSME",                      
                     trControl = control) 

# Make predictions on the test set
SPARC_gbm_preds <- predict(SPARC_gbm, newdata = test_set[,c(2:2049, 2051:2060)], type = "raw")


#Generate confusion matrix
cm_SPARC_gbm = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_gbm_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_gbm <- merge(tile_plot_df[match(cm_SPARC_gbm$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_gbm, by = "tile_name")

mse =  mean((cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred))
rmse = sum((cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred)^2)/sum((cm_SPARC_gbm$SPARC - mean(cm_SPARC_gbm$SPARC))^2)
r2 = R2(cm_SPARC_gbm$SPARC, cm_SPARC_gbm$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Polt predict expression
ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
```


```{r}
SPARC_gbm <- caret::train(SPARC~.,                      
                     data = training_set[,c(2050:2052)],    #training_set[,-c(1,2007)]                
                     method = "gbm",                      
                     metric = "RSME",                      
                     trControl = control) 

# Make predictions on the test set
SPARC_gbm_preds <- predict(SPARC_gbm, newdata = test_set[,c(2051, 2052)], type = "raw")


#Generate confusion matrix
cm_SPARC_gbm = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_gbm_preds, tile_name = test_set[,1])

# Combine the original expression value and predict values with tile coordinates
cm_SPARC_gbm <- merge(tile_plot_df[match(cm_SPARC_gbm$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_gbm, by = "tile_name")

mse =  mean((cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred)^2) 
mae = mean(abs(cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred))
rmse = sum((cm_SPARC_gbm$SPARC - cm_SPARC_gbm$SPARC_pred)^2)/sum((cm_SPARC_gbm$SPARC - mean(cm_SPARC_gbm$SPARC))^2)
r2 = R2(cm_SPARC_gbm$SPARC, cm_SPARC_gbm$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Polt predict expression
ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

ggplot(cm_SPARC_gbm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
```




#Model4:  SVM
```{r}
#Use the SVM model 
SPARC_svm <- caret::train(SPARC~.,                      
                     data = training_set[,c(2:2049,2050)],    #training_set[,-c(1,2007)]
                     method = "svmPoly",                      
                     metric = "RMSE",                      
                     trControl = control) 

# Predicting the Test set results (without giving it real expression value)
#APOE_pred = predict(svm_mod_APOE , newdata = test_set[,-c(1,10,11)])
SPARC_svm_preds = predict(SPARC_svm , newdata = test_set[,c(2:2049)])

#Generate confusion matrix
cm_SPARC_svm = data.frame( SPARC = test_set["SPARC"], SPARC_pred = SPARC_svm_preds, tile_name = test_set[,1]) #APOE = test_set[10]


# Combine the original expression value and predict values with tile coordinates
cm_SPARC_svm <- merge(tile_plot_df[match(cm_SPARC_svm$tile_name, tile_plot_df$tile_name),c("cell_ID","tile_name","x_cor","y_cor")], cm_SPARC_svm, by = "tile_name")


mse =  mean((cm_SPARC_svm$SPARC - cm_SPARC_svm$SPARC_pred))
rmse = sum((cm_SPARC_svm$SPARC - cm_SPARC_svm$SPARC_pred)^2)/sum((cm_SPARC_svm$SPARC - mean(cm_SPARC_svm$SPARC))^2)
r2 = R2(cm_SPARC_svm$SPARC, cm_SPARC_svm$SPARC_pred, form = "corr")
cat(" MAE:", mae, "\n", "MSE:", mse, "\n", 
    "RMSE:", rmse, "\n", "R-squared:", r2)

#Polt predict expression
ggplot(cm_SPARC_svm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC_preds)) +
  scale_colour_gradient2()

ggplot(cm_SPARC_svm, aes(x=x_cor, y=y_cor)) +
  geom_point(aes(colour = SPARC)) +
  scale_colour_gradient2()
```
#Using the following code to debug 
```{r}

plot(test_set$APOE, APOE_rf_preds)
scatter.smooth(test_set$APOE, APOE_rf_preds)
cor(test_set$APOE, APOE_rf_preds)
```


